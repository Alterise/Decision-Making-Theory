\documentclass{article}

\usepackage{cmap}					
\usepackage{mathtext} 				
\usepackage[T2A]{fontenc}			
\usepackage[utf8]{inputenc}	
\usepackage[english,russian]{babel}	
\usepackage{indentfirst}
\frenchspacing

\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\title{Курсовая Работа по ТПР}
\author{Терешков Алексей, Алимов Исмаил, Мамченков Дмитрий}
\date{}

\begin{document}
\maketitle

\section{Задача}
Рассмотрим алгоритм экспоненциального взвешивания на основе градиента с переменным шагом обучения. Приведите исчерпывающие выкладки и получите оценку на кумулятивный регрет. Как следует выбирать параметр обучения на каждом шаге?

\section{Решение}
Алгоритм экспоненциального взвешивания на основе градиента с переменным шагом обучения (EWGD) применяется для минимизации функционала потерь в задачах оптимизации. Этот алгоритм является модификацией стандартного метода градиентного спуска, в котором используется переменный шаг обучения, зависящий от номера итерации. \\

Пусть дана функция потерь $f(w)$, которую необходимо минимизировать по параметру $w$. Тогда на каждом шаге алгоритма мы вычисляем градиент функции $f(w)$ и изменяем параметр $w$ следующим образом: \\
\[w_{t+1}=W_t-\alpha _t\nabla f(w_t),\]
где $\alpha _t$ - шаг обучения на шаге $t$, который может меняться на каждой итерации. \\

В алгоритме EWGD шаг обучения задается следующим образом:
\[\alpha _t = \frac{\eta}{\sqrt{\sum ^t_{i=1}g^2_i}},\]
где $\eta$ - параметр скорости обучения, $g_i$ - градиент функции на $i$-ой итерации. \\

\end{document}
